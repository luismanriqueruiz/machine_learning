{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries\n",
    "\n",
    "[Link](https://github.com/davidberenstein1957/classy-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# or import standalone\n",
    "# from classy_classification import ClassyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"furniture\": [\"This text is about chairs.\",\n",
    "               \"Couches, benches and televisions.\",\n",
    "               \"I really need to get a new sofa.\"],\n",
    "    \"kitchen\": [\"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis-carlos/Documents/experiments/llm_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/luis-carlos/Documents/experiments/llm_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from spacy_curated_transformers.pipeline.transformer import DEFAULT_CONFIG\n",
    "\n",
    "#@Language.component #` (for function components) or `@Language.factory`\n",
    "#nlp.add_pipe(\"curated_transformer\", config=DEFAULT_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis-carlos/Documents/experiments/llm_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'classy_classification' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, ja.morphologizer, curated_transformer, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_trf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassy_classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspacy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/experiments/llm_env/lib/python3.12/site-packages/spacy/language.py:821\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    817\u001b[0m     pipe_component, factory_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_pipe_from_source(\n\u001b[1;32m    818\u001b[0m         factory_name, source, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    819\u001b[0m     )\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 821\u001b[0m     pipe_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactory_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m pipe_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_meta[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[0;32m~/Documents/experiments/llm_env/lib/python3.12/site-packages/spacy/language.py:690\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    683\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE002\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    684\u001b[0m         name\u001b[38;5;241m=\u001b[39mfactory_name,\n\u001b[1;32m    685\u001b[0m         opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    688\u001b[0m         lang_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang,\n\u001b[1;32m    689\u001b[0m     )\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    691\u001b[0m pipe_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: [E002] Can't find factory for 'classy_classification' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, ja.morphologizer, curated_transformer, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "nlp.add_pipe(\n",
    "    \"classy_classification\",\n",
    "    config={\n",
    "        \"data\": data,\n",
    "        \"model\": \"spacy\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp(\"I am looking for kitchen appliances.\")._.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence level classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\n",
    "    \"classy_classification\",\n",
    "    config={\n",
    "        \"data\": data,\n",
    "        \"model\": \"spacy\",\n",
    "        \"include_sent\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(nlp(\"I am looking for kitchen appliances. And I love doing so.\").sents[0]._.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"furniture\": [\"This text is about chairs.\",\n",
    "               \"Couches, benches and televisions.\",\n",
    "               \"I really need to get a new sofa.\",\n",
    "               \"We have a new dinner table.\",\n",
    "               \"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\",\n",
    "                \"We have a new dinner table.\"],\n",
    "    \"kitchen\": [\"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\",\n",
    "                \"We have a new dinner table.\",\n",
    "                \"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\",\n",
    "                \"We have a new dinner table.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.add_pipe(\n",
    "    \"classy_classification\",\n",
    "    config={\n",
    "        \"data\": data,\n",
    "        \"model\": \"spacy\",\n",
    "        \"multi_label\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(nlp(\"I am looking for furniture and kitchen equipment.\")._.cats)\n",
    "\n",
    "# Output:\n",
    "#\n",
    "# [{\"furniture\": 0.92}, {\"kitchen\": 0.91}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-transfomer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"furniture\": [\"This text is about chairs.\",\n",
    "               \"Couches, benches and televisions.\",\n",
    "               \"I really need to get a new sofa.\"],\n",
    "    \"kitchen\": [\"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\n",
    "    \"classy_classification\",\n",
    "    config={\n",
    "        \"data\": data,\n",
    "        \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        \"device\": \"gpu\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(nlp(\"I am looking for kitchen appliances.\")._.cats)\n",
    "\n",
    "# Output:\n",
    "#\n",
    "# [{\"furniture\": 0.21}, {\"kitchen\": 0.79}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classy_classification import ClassyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classyClassifier(data=data)\n",
    "\n",
    "with open(\"./classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)\n",
    "\n",
    "f = open(\"./classifier.pkl\", \"rb\")\n",
    "classifier = pickle.load(f)\n",
    "classifier(\"I am looking for kitchen appliances.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
